{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointer Network Training\n",
    "In this notebook we are going to train the pointer network with a 10% sample of the CNN dataset we processed in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from src import PointerNetwork\n",
    "from src import load_pretrained_embeddings\n",
    "from src import train_model, evaluate_model\n",
    "\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "We load all the data here. We have X for the processed stories, y for the labels, gen for remembering us if a label is to be generated or to be taken from the input, and y_raw are the same as y, without having indexes pointng to X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('processed/X_train.npy')\n",
    "y_train = np.load('processed/y_train.npy')\n",
    "gen_train = np.load('processed/gen_train.npy').astype('float32')\n",
    "y_raw_train = np.load('processed/y_raw_train.npy')\n",
    "\n",
    "X_val = np.load('processed/X_val.npy')\n",
    "y_val = np.load('processed/y_val.npy')\n",
    "gen_val = np.load('processed/gen_val.npy').astype('float32')\n",
    "y_raw_val = np.load('processed/y_raw_val.npy')\n",
    "\n",
    "X_test = np.load('processed/X_test.npy')\n",
    "y_test = np.load('processed/y_test.npy')\n",
    "gen_test = np.load('processed/gen_test.npy').astype('float32')\n",
    "y_raw_test = np.load('processed/y_raw_test.npy')\n",
    "\n",
    "w2id = load(open('processed/w2id.pkl', 'rb'))\n",
    "id2w = load(open('processed/id2w.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.data.Dataset.from_tensor_slices((X_train, y_train, gen_train))\n",
    "train_generator = train_generator.batch(32)\n",
    "train_generator = train_generator.shuffle(1000)\n",
    "\n",
    "val_generator = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_generator = val_generator.batch(32)\n",
    "val_generator = val_generator.shuffle(1000)\n",
    "\n",
    "test_generator = tf.data.Dataset.from_tensor_slices((X_test, y_raw_test))\n",
    "test_generator = test_generator.batch(32)\n",
    "test_generator = test_generator.shuffle(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "We instantiate the newtwork with this dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "enc_units = 128\n",
    "dec_units = 128\n",
    "voc_size = len(w2id.keys())\n",
    "att_units = 128 \n",
    "switch_units = 128\n",
    "max_len = X_train.shape[1]\n",
    "start_index_token = w2id['<start>']\n",
    "end_index_token = w2id['<end>']\n",
    "padding_char = w2id['<pad>']\n",
    "ptr = PointerNetwork(enc_units, \n",
    "                     dec_units, \n",
    "                     voc_size, \n",
    "                     att_units, \n",
    "                     switch_units, \n",
    "                     max_len, \n",
    "                     start_index_token, \n",
    "                     end_index_token,\n",
    "                     padding_char)\n",
    "\n",
    "ptr.set_embeddings_layer(load_pretrained_embeddings(np.zeros((voc_size,voc_size))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = ['loss']\n",
    "val_metric_names = ['rouge-1-p', 'rouge-1-r', 'rouge-1-f', \n",
    "                    'rouge-2-p', 'rouge-2-r', 'rouge-2-f', \n",
    "                    'rouge-l-p', 'rouge-l-r', 'rouge-l-f', ]\n",
    "val_best_metric = 'rouge-2-f'\n",
    "training_size = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(ptr, train_generator, val_generator, X_train.shape[0], \n",
    "            EPOCHS, BATCH_SIZE, metric_names, val_metric_names, \n",
    "            val_best_metric, smooth_window=1, weights_dir='./weights',\n",
    "            log_dir='./logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(ptr, test_generator, val_metric_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
