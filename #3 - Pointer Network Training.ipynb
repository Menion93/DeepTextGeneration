{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointer Network Training\n",
    "In this notebook we are going to train the pointer network with a 10% sample of the CNN dataset we processed in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from src import PointerNetwork\n",
    "from src import load_pretrained_embeddings\n",
    "\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "We load all the data here. We have X for the processed stories, y for the labels, gen for remembering us if a label is to be generated or to be taken from the input, and y_raw are the same as y, without having indexes pointng to X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('processed/X_train.npy')\n",
    "y_train = np.load('processed/y_train.npy')\n",
    "gen_train = np.load('processed/gen_train.npy').astype('float32')\n",
    "y_raw_train = np.load('processed/y_raw_train.npy')\n",
    "\n",
    "X_val = np.load('processed/X_val.npy')\n",
    "y_val = np.load('processed/y_val.npy')\n",
    "gen_val = np.load('processed/gen_val.npy').astype('float32')\n",
    "y_raw_val = np.load('processed/y_raw_val.npy')\n",
    "\n",
    "X_test = np.load('processed/X_test.npy')\n",
    "y_test = np.load('processed/y_test.npy')\n",
    "gen_test = np.load('processed/gen_test.npy').astype('float32')\n",
    "y_raw_test = np.load('processed/y_raw_test.npy')\n",
    "\n",
    "w2id = load(open('processed/w2id.pkl', 'rb'))\n",
    "id2w = load(open('processed/id2w.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.data.Dataset.from_tensor_slices((X_train, y_train, gen_train))\n",
    "train_generator = train_generator.batch(32)\n",
    "train_generator = train_generator.shuffle(1000)\n",
    "\n",
    "val_generator = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_generator = val_generator.batch(32)\n",
    "val_generator = val_generator.shuffle(1000)\n",
    "\n",
    "test_generator = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_generator = test_generator.batch(32)\n",
    "test_generator = test_generator.shuffle(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "We instantiate the newtwork with this dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "enc_units = 128\n",
    "dec_units = 128\n",
    "voc_size = len(w2id.keys())\n",
    "att_units = 128 \n",
    "switch_units = 128\n",
    "max_len = X_train.shape[1]\n",
    "start_index_token = w2id['<start>']\n",
    "end_index_token = w2id['<end>']\n",
    "padding_char = w2id['<pad>']\n",
    "ptr = PointerNetwork(enc_units, \n",
    "                     dec_units, \n",
    "                     voc_size, \n",
    "                     att_units, \n",
    "                     switch_units, \n",
    "                     max_len, \n",
    "                     start_index_token, \n",
    "                     end_index_token,\n",
    "                     padding_char)\n",
    "\n",
    "ptr.set_embeddings_layer(load_pretrained_embeddings(np.zeros((voc_size,voc_size))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = ['loss']\n",
    "training_size = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def progress_eta(count, total, prev_time, c_time, prev_mean, status=''):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = min(100, round(100.0 * count / float(total), 1))\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "    \n",
    "    current_batch_time = c_time-prev_time\n",
    "    mean = (1-1/count) * prev_mean + (1/count)*current_batch_time\n",
    "    eta = int((total - count) * mean)\n",
    "    eta_str = str(datetime.timedelta(seconds=eta))\n",
    "\n",
    "    print('[{0}] {1}{2} \\t{3}\\tETA: {4}'.format(bar, percents, '%', status, eta_str), end='')\n",
    "    print('\\r', end='')\n",
    "    return mean\n",
    "\n",
    "def log_scalar(name, value):\n",
    "    with tf.contrib.summary.always_record_summaries():\n",
    "        tf.contrib.summary.scalar(name, value)\n",
    "\n",
    "def setup_tensoroard(log_dir):\n",
    "    summary_writer = tf.contrib.summary.create_file_writer(log_dir, flush_millis=10000)\n",
    "    summary_writer.set_as_default()\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    return global_step\n",
    "\n",
    "def train_model(model, train_generator, val_generator, training_size, epochs, batch_size,\n",
    "                metric_names, best_model_metric, smooth_window=25, weights_dir='./', log_dir='./log'):\n",
    "    \n",
    "    assert best_model_metric in metric_names\n",
    "    \n",
    "    data = {\n",
    "        'current_score': 0,\n",
    "        'best_score': 0,\n",
    "        'start': time.clock(),\n",
    "        'end': 0,\n",
    "        'mean': 0,\n",
    "        'prev_time': 0,\n",
    "        'num_iterations': math.ceil(training_size / batch_size),\n",
    "        'window': smooth_window\n",
    "    }\n",
    "    \n",
    "    # Setup Metrics and Logging\n",
    "    init_metrics = lambda: dict([(name,[]) for name in metric_names])\n",
    "    \n",
    "    print('Start training...')\n",
    "    print(\"Number of iterations per epoch is: \" + str(data['num_iterations']))\n",
    "    print()\n",
    "\n",
    "    # Tensorboard setup\n",
    "    global_step = setup_tensoroard(log_dir)\n",
    "    data['global_step'] = global_step\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        # Init metrics to log\n",
    "        metrics = init_metrics()\n",
    "\n",
    "        # Start Training Epoch\n",
    "        train_epoch(model, train_generator, epoch, metrics, data)\n",
    "        \n",
    "        # Validate Last Epoch\n",
    "        val_epoch(model, val_generator, epoch, metric_names, \n",
    "                  best_model_metric, weights_dir, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_batch(metrics, i, epoch, data):\n",
    "    if i > data['window']:\n",
    "        metrics_string = 'Epoch: {}'.format(epoch)\n",
    "\n",
    "        # Tensorboard add step\n",
    "        data['global_step'].assign_add(1)\n",
    "\n",
    "        for m_name, m_lst in  metrics.items():\n",
    "            metrics[m_name] = metrics[m_name][:window]\n",
    "            log_scalar(m_name, np.mean(m_lst))\n",
    "            metrics_string += '\\t{0}: {1:.2}'.format(m_name, np.mean(m_lst))\n",
    "\n",
    "        # print progress\n",
    "        data['mean'] = progress_eta(i + 1 - data['window'], \n",
    "                                data['num_iterations']-data['window'],\n",
    "                                data['prev_time'], \n",
    "                                data['c_time'],\n",
    "                                data['mean'], \n",
    "                                metrics_string)\n",
    "        data['prev_time'] = data['c_time']\n",
    "\n",
    "def train_epoch(model, train_generator, epoch, metrics, data):\n",
    "    for iteration, args in enumerate(train_generator):\n",
    "        data['prev_time'] = time.time()\n",
    "        # Do a train step on a single batch\n",
    "        logs = model.train_on_batch(*args)\n",
    "        data['c_time'] = time.time()\n",
    "\n",
    "        for metric, (_, lst) in zip(logs, metrics.items()):\n",
    "            lst.insert(0, metric)\n",
    "        \n",
    "        log_batch(metrics, iteration, epoch, data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(model, val_generator, epoch, metrics, best_model_metric, weights_dir, data):\n",
    "    total_metrics = dict([('val_' + metric, []) for metric in metrics])\n",
    "    mean_metrics = {}\n",
    "\n",
    "    # Compute validation in batches\n",
    "    for args in val_generator:\n",
    "        metrics_ = model.evaluate(*args, verbose=0)\n",
    "\n",
    "        for i, metric in enumerate(metrics_):\n",
    "            total_metrics['val' + metrics[i]].append(metric)\n",
    "\n",
    "\n",
    "    # Average results & Log on Tensorboard\n",
    "    for key, total_metric in total_metrics.items():\n",
    "        mean_metrics[key] = np.mean(total_metric)\n",
    "        log_scalar(key, mean_metrics[key])\n",
    "\n",
    "    # Check best score and swap if better\n",
    "    data['current_score'] = mean_metrics['val' + best_model_metric]\n",
    "\n",
    "    print()\n",
    "\n",
    "    # Check for improvement and save the best model\n",
    "    if data['current_score'] > data['best_score']:\n",
    "        model.save_weights(\"{0}weights.{1}-{2}.hdf5\"\n",
    "                           .format(weights_dir, str(epoch), str(data['current_score'])))\n",
    "        data['best_score'] = data['current_score']\n",
    "        print(\"Saved. \")\n",
    "\n",
    "    print(\"Validation Accuracy in is {0:.6f} at epoch {1}\"\\\n",
    "          .format(np.mean(mean_metrics['val_acc']), epoch))\n",
    "    print(\"Validation Top K Accuracy is {0:.6f} at epoch {1}\"\\\n",
    "          .format(np.mean(mean_metrics['val_top_k']), epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Number of iterations per epoch is: 223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(ptr, train_generator, val_generator, X_train.shape[0], \n",
    "            EPOCHS, BATCH_SIZE, metric_names, 'loss', weights_dir='./weights',\n",
    "            log_dir='./logs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
